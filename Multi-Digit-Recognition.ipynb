{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Digit Recognition from Images\n",
    "\n",
    "In this project you need to build a deep neural network for multi-digit recognition task. Specifically, each of the input images contains a 3 digit number. You have to identify all the digits present in the image. One way to do this is to use a neural network which has 3 output branches (see the figure below).\n",
    "\n",
    "![](digit-recognition.png)\n",
    "\n",
    "\n",
    "You are provided with the base code which contains the dataloader part and other training module. You have build a model which is as light as possible but should give the best accuracy :)\n",
    "\n",
    "You can modify the learning rate, optimizer, layers, number of nodes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_samples(image, digit):\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1:** You have to write the Resize Class manually\n",
    "#### Refer:\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['digit']\n",
    "        h, w = image.shape\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        return {'image': img, 'digit': label}\n",
    "\n",
    "class Resize(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or tuple): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # You code goes here\n",
    "        return {'image': img, 'digit': label}\n",
    "    \n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['digit']\n",
    "        h, w = image.shape # changed from [:2] to nothing as the images are gray scale\n",
    "        new_h, new_w = self.output_size\n",
    "        \n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "\n",
    "\n",
    "        return {'image': image, 'digit': label}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['digit']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image[np.newaxis,:,:]\n",
    "        return {'image': torch.from_numpy(image).float(), 'digit': (torch.from_numpy(np.array([label])))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class ThreeGramDigitDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, gt_file, dataset_root, shuffle = False, transform = None):\n",
    "        \n",
    "        self.dataset_root = dataset_root\n",
    "        self.all_file_names = [x.split(' ')[0] for x in open(gt_file).readlines()]\n",
    "        self.labels = [int(x.split(' ')[1]) for x in open(gt_file).readlines()]\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.all_file_names, self.labels))\n",
    "            random.shuffle(temp)\n",
    "            self.all_file_names, self.labels = zip(*temp)\n",
    "        \n",
    "        self.transform = transform\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_file_names)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_name = os.path.join(self.dataset_root, self.all_file_names[idx])\n",
    "        image = io.imread(img_name)\n",
    "        sample = {'image': image, 'digit': self.labels[idx]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ThreeGramDigitDataset('/tmp/step/data/3Gram_ann_train.txt', '/tmp/step/data/3Gram_Digits', shuffle = False)\n",
    "#printing the no. of training samples\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    sample = train_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(str(sample['digit'])))\n",
    "    ax.axis('off')\n",
    "    show_samples(**sample) # way of passing a dictionary\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scale = Rescale(256)\n",
    "crop = RandomCrop(64)\n",
    "composed = transforms.Compose([Rescale(99),Resize((64,128))])\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "fig = plt.figure()\n",
    "sample = train_dataset[1]\n",
    "\n",
    "for i, tsfrm in enumerate([scale, composed]):\n",
    "    print(tsfrm)\n",
    "    print(i)\n",
    "    transformed_sample = tsfrm(sample)\n",
    "    print(transformed_sample['image'].shape)\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    show_samples(**transformed_sample)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ThreeGramDigitDataset('/tmp/step/data/3Gram_ann_train.txt', '/tmp/step/data/3Gram_Digits',\n",
    "                                          shuffle = True, transform=transforms.Compose([\n",
    "                                               Resize((64,128)),\n",
    "                                               ToTensor()\n",
    "                                           ]))\n",
    "test_dataset = ThreeGramDigitDataset('/tmp/step/data/3Gram_ann_train.txt', '/tmp/step/data/3Gram_Digits',\n",
    "                                          shuffle = True, transform=transforms.Compose([\n",
    "                                               Resize((64,128)),\n",
    "                                               ToTensor()\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch the dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=1)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=4,\n",
    "                        shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "import pdb\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Define Layers here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define Architectures here\n",
    "        return x1, x2, x3\n",
    "    \n",
    "model = Net().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "\n",
    "plotIter = 2000\n",
    "plotIterCntr = 0\n",
    "numEpochs = 10\n",
    "trainLoss = np.zeros((plotIter*numEpochs,1))\n",
    "trainIter = np.arange(plotIter*numEpochs)\n",
    "\n",
    "for epoch in range(numEpochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        \n",
    "        # get the inputs\n",
    "        inputs, labels = data['image'], data['digit']\n",
    "        \n",
    "        #get each label separately\n",
    "        labels_1 = torch.div(labels, 100)\n",
    "        labels_2 = torch.div(torch.fmod(labels, 100), 10)\n",
    "        labels_3 = torch.fmod(torch.fmod(labels, 100), 10)\n",
    "        \n",
    "        # wrap them in Variable\n",
    "        inputs, labels_1, labels_2, labels_3 = Variable(inputs.cuda()),Variable(labels_1.cuda()), Variable(labels_2.cuda()), Variable(labels_3.cuda())\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs_1, outputs_2, outputs_3 = model(inputs)\n",
    "        loss = criterion(outputs_1, labels_1[:,0])+criterion(outputs_2, labels_2[:,0])+criterion(outputs_3, labels_3[:,0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        if i % plotIter == plotIter-1:    # print every plotIter mini-batches\n",
    "            trainLoss[plotIterCntr] = running_loss / plotIter\n",
    "            plotIterCntr+=1\n",
    "            \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / plotIter))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "plt.plot(np.arange(plotIterCntr)*plotIter,trainLoss[0:plotIterCntr], label=\"train\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction of accuracy\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "#Iterating over the batches returned from testloader\n",
    "for data in test_dataloader:\n",
    "    images, labels = data['image'], data['digit']\n",
    "        \n",
    "    outputs_1, outputs_2, outputs_3 = model(Variable(images.cuda()))\n",
    "    \n",
    "    _, predicted_1 = torch.max(outputs_1.data, 1)\n",
    "    _, predicted_2 = torch.max(outputs_2.data, 1)\n",
    "    _, predicted_3 = torch.max(outputs_3.data, 1)\n",
    "    \n",
    "    predicted = predicted_1.mul(100) + predicted_2*10 + predicted_3\n",
    "\n",
    "    total += labels.size(0)\n",
    "    labels = labels.cuda()\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 1350 test images: %d %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
